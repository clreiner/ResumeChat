{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf381fb0-6bc3-455d-947e-0abc30ebec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch # do I need permanent storage like pinecone?\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "MODEL = \"gemma3\"\n",
    "MODEL_EMBED = \"embeddinggemma\"\n",
    "DOCUMENTS = \"resume2025.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44ce0f01-f074-4c16-a5da-e3db8bb6efef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay! Iâ€™m not thinking of an elephant. ðŸ˜Š \\n\\nIs there anything you *are* thinking about, or would you like me to do something else?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instanciate & test model\n",
    "model = OllamaLLM(model=MODEL)\n",
    "model.invoke(\"Don't think of an elephant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c52d99c-27a5-47b0-ad3d-b844cee69e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = PyPDFLoader(DOCUMENTS)\n",
    "pages = loader.load_and_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c48fbde-b9f3-449e-9ee0-370f95cca388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnswer the question based on the context below. If you can\\'t \\nanswer the question, reply \"I don\\'t know\".\\n\\nContext: I need a Data Scientist\\n\\nQuestion: Is this a good fit\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "template = '''\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt.format(context=\"I need a Data Scientist\", question=\"Is this a good fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0553bb0a-0e4d-4dc5-b698-51a5665f74d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b56ad256-0548-4126-8209-741a9d3bf01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/qtr66ng91gj6czktr43rbl4h0000gn/T/ipykernel_42747/3226659032.py:1: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  chain.input_schema.schema()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'properties': {'context': {'title': 'Context', 'type': 'string'},\n",
       "  'question': {'title': 'Question', 'type': 'string'}},\n",
       " 'required': ['context', 'question'],\n",
       " 'title': 'PromptInput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f8fb753-f615-481f-b828-8da22b008833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cindyreiner/Documents/Code/local-LLM/.venv/lib/python3.13/site-packages/docarray/helper.py:255: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  e.g. '\\*.py', '[\\*.zip, \\*.gz]'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=MODEL_EMBED)\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(pages, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab5324a3-85a9-4273-9ab3-6dedc9d41d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "080da942-6885-4d35-acf0-ffa01be8479b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the resume content, the following soft skills are evident:\n",
      "\n",
      "*   **Cross-functional Leadership:** Demonstrated in her roles at Booz Allen Hamilton and Jovial.\n",
      "*   **Stakeholder Management:** Highlighted in multiple roles, particularly at Booz Allen Hamilton and Jovial.\n",
      "*   **Technical Writing & Editing:** Mentioned as a key skill.\n",
      "*   **Communication:** Implicit through her presentations, technical documentation, and collaboration.\n",
      "*   **Grant Writing:** Explicitly listed as a skill.\n",
      "*   **Research Methodology:** Demonstrated throughout her academic and research experience.\n",
      "*   **Presentations:** Mentioned as a key skill.\n",
      "Based on the provided resume, Cindy Reiner appears to be a strong fit for a data scientist role. Hereâ€™s a breakdown of why:\n",
      "\n",
      "*   **Relevant Experience:** She has 8+ years of experience in quantitative analysis and research, combined with 4 years of machine learning implementation.\n",
      "*   **Technical Skills:** She possesses a strong skillset including Python, SQL, Pandas, NumPy, Keras, TensorFlow, AWS, Google Cloud, and various data science tools.\n",
      "*   **Project Experience:** Her experience at Flatiron School and her work with Booz Allen Hamilton demonstrate practical application of data science techniques. Notably, her work on the topic modeling tool and the contract analysis chatbot are relevant.\n",
      "*   **Achievements:** Her key achievements, such as reducing literature review time and automating dataset integration, highlight her ability to deliver measurable impact.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    | prompt\n",
    "    | model\n",
    "    \n",
    ")\n",
    "\n",
    "print(chain.invoke({\"question\": \"what soft skills are evident\"}))\n",
    "print(chain.invoke({\"question\": \"would she be a good fit for our data scientist role\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7439875-2f88-45a3-9eb0-2d322ab017b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
